# Epic 1.5 Retrospective: Public Landing Page

**Date:** 2026-02-12
**Facilitator:** Bob (Scrum Master)
**Epic:** Epic 1.5 — Public Landing Page (B-Lite Strategy)
**Status:** Complete (3/3 stories done)

## Participants

- Keith (Project Lead)
- John (Product Manager)
- Bob (Scrum Master)
- Charlie (Senior Dev)
- Dana (QA Engineer)
- Sally (UX Designer)

## Epic 1.5 Summary

### Delivery Metrics

- Stories Completed: 3/3 (100%)
- Stories Approved on First Review: 3/3
- Blockers Encountered: 1 (jsdom limitation with `<html>` rendering)
- Technical Debt Items: 1 (placeholder OG image — addressed during retro)
- Production Incidents: 0
- Test Count: 41 tests passing

### Stories Delivered

| Story | Title | Status | Model Used |
|-------|-------|--------|------------|
| 1-5-1 | Landing Page Foundation | Done | Claude Opus 4.6 |
| 1-5-2 | SEO & Analytics Foundation | Done | Claude Opus 4.6 |
| 1-5-3 | App Launch Integration | Done | Claude Opus 4.6 |

## Previous Retrospective Follow-Through

**Epic 1 Retrospective Action Items:**

| # | Action | Status | Evidence |
|---|--------|--------|----------|
| 1 | Story scoping cross-reference | ✅ Done | Stories 1-5-1 through 1-5-3 scoped cleanly, no overlap |
| 2 | Task checkbox verification in story-done | ✅ Done | All stories have checkboxes properly marked |
| 3 | Document Supabase dev gotchas | N/A | Epic 1.5 has no Supabase dependencies |

**Technical Debt from Epic 1:**

| # | Item | Status |
|---|------|--------|
| 1 | Zero test infrastructure | ✅ Resolved | Vitest + jsdom configured, 41 tests passing, CI integrated |

All commitments from Epic 1 retro were honored. Test infrastructure — the highest-priority debt item — was fully resolved as a preparation task before Epic 1.5 started.

## What Went Well

1. **100% completion rate** — All 3 stories approved on first review
2. **Test infrastructure established** — 41 tests passing across components, SEO metadata, analytics, and structured data
3. **Clean B-Lite architecture** — Static export with `output: "export"` works flawlessly; no server-side complexity
4. **Sanctuary Serenity theme** — Visual design polished to match UX spec with gradients, glassmorphism cards, hero painting, and gold accent system
5. **Privacy-first analytics** — Plausible integration with custom events, no Google tracking, GDPR-compliant from day one
6. **SEO completeness** — OG tags, Twitter Cards, JSON-LD structured data, sitemap.xml, robots.txt all in place
7. **Hero painting** — Kauffmann's "Christ and the Samaritan Woman at the Well" as background image perfectly correlates with the "Seek and Find" mission

## Challenges

1. **Visual design quality gap** — Initial implementation was technically correct (all CSS classes present, tests passing) but visually bland. Keith caught this during manual review. 41 tests passed but couldn't evaluate aesthetic quality.
2. **jsdom limitation** — Cannot render `<html>` in jsdom, requiring alternative test approaches for layout metadata. Worked around with direct export testing.
3. **Hero painting iteration** — First implementation rendered the painting as a side card instead of a background image. Required 3 iterations (side card → background with 75% overlay → background with 60% overlay) before Keith approved.
4. **OG image placeholder** — Started with a programmatically generated placeholder. Replaced during retro with cropped Kauffmann painting.

## Key Insights

1. **Automated tests verify code correctness; human testing verifies the product works.** These are complementary, not interchangeable. 41 tests passed but the page looked "super bland" — only Keith's visual review caught the design gap.
2. **Static export simplifies everything** — No SSR edge cases, no server component confusion. The B-Lite strategy for the landing page was the right call.
3. **Tailwind CSS 4's `@theme` directive** is clean for design token management. All Sanctuary Serenity colors defined once and used throughout.
4. **Art selection matters** — The Kauffmann painting elevated the landing page from generic to mission-aligned. Traditional Catholic art reinforces brand identity.
5. **Iterative visual refinement requires human-in-the-loop** — AI can implement CSS but cannot judge aesthetic quality. Keith's eye was essential for overlay opacity, glow intensity, and edge treatment decisions.

## Action Items

### Process Improvements

| # | Action | Owner | Success Criteria |
|---|--------|-------|-----------------|
| 1 | Add visual/design quality gate to story ACs | Bob (SM) | Every story with UI output includes "Keith visual approval" as an AC |
| 2 | Document manual vs. CI test boundaries in every story | Bob (SM) | Dev Notes template includes manual testing checklist |
| 3 | Re-introduce code review step before marking stories done | Bob (SM) | Code review workflow runs on every story |

### Technical Debt

| # | Item | Priority | Owner |
|---|------|----------|-------|
| 1 | OG image is cropped painting — may need branded version later | LOW | Keith (manual) |

## Epic 2 Preparation Tasks

### Technical Setup

- [ ] Run `epic-tech-context` for Epic 2 (Audio Player) — Owner: Bob (SM)
- [ ] Evaluate `react-native-track-player` vs alternatives for background audio — Owner: Charlie (Dev)
- [ ] Seed test audio content in Supabase for development — Owner: Charlie (Dev)
- [ ] Confirm Keith's device testing setup (physical iOS + Android devices) — Owner: Keith

### Knowledge Development

- [ ] Research Expo Audio API capabilities and limitations — Owner: Charlie (Dev)
- [ ] Document lock screen control integration requirements per platform — Owner: Charlie (Dev)

### Critical Path

- [ ] Keith must verify audio playback on physical iOS device before any audio story is marked done
- [ ] Keith must verify audio playback on physical Android device before any audio story is marked done

## Epic 2 Preview

**Epic 2: Audio Player**

- 6 stories planned (basic playback → background audio → speed control → skip → mini player → position tracking)
- Goal: Core audio playback experience across web, iOS, and Android
- **Critical difference from Epic 1.5**: Audio features MUST be tested on physical devices. Automated tests cannot verify audio playback, background behavior, or lock screen controls.
- Dependencies: Epic 1 (Supabase, database schema) — complete

### Significant Discoveries

No architectural changes needed for Epic 2. The foundation from Epic 1 and the B-Lite static landing page from Epic 1.5 are solid. However, the key learning from Epic 1.5 — **human-in-the-loop testing is essential** — becomes even more critical for Epic 2, where native device behavior cannot be simulated in CI.

## Readiness Assessment

| Area | Status |
|------|--------|
| Testing & Quality | 41 tests passing; Vitest + CI integrated; manual testing philosophy documented |
| Deployment | CI/CD operational; Vercel preview and production deploys working |
| Technical Health | Codebase clean; no fragility; static export stable |
| Unresolved Blockers | None |

## Next Steps

1. Execute Epic 2 preparation tasks (tech context, audio library evaluation, test audio seeding)
2. Review action items in next standup
3. Begin Epic 2 when preparation complete — run `epic-tech-context` for Epic 2

---

## Change Log

| Date | Change | Author |
|------|--------|--------|
| 2026-02-12 | Retrospective completed | Bob (SM) / Keith (Project Lead) |
